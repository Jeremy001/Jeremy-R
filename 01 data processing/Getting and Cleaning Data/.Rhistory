html("http://en.wikipedia.org/wiki/Table_(information)") %>%
html.node(".wikitable") %>%
html_table()
read_html("http://en.wikipedia.org/wiki/Table_(information)") %>%
html.node(".wikitable") %>%
html_table()
read_html("http://en.wikipedia.org/wiki/Table_(information)") %>%
html_node(".wikitable") %>%
html_table()
read_html("http://en.wikipedia.org/wiki/Table_(information)") %>%
html_nodes(".wikitable") %>%
html_table()
read_html("http://www.sec.gov/litigation/suspensions.shtml") %>%
html_node("p + table a") %>%
head()
read_html("http://www.sec.gov/litigation/suspensions.shtml") %>%
html_node("p + table a")
read_html("http://www.sec.gov/litigation/suspensions.shtml") %>%
html_nodes("p + table a") %>%
head()
test <- read_html("http://www.sec.gov/litigation/suspensions.shtml") %>%
html_nodes("p + table a") %>%
head()
dim(test)
str(test)
class(test)
test[1]
test[2]
test[2]
test[3]
read_html("http://stat.iastate.edu/people/3") %>%
html_nodes("a") %>%
head()
read_html("http://stat.iastate.edu/people/3") %>%
html_nodes("# content a") %>%
head()
read_html("http://stat.iastate.edu/people/3") %>%
html_nodes("#content a") %>%
head()
read_html("http://stat.iastate.edu/people/3") %>%
html_nodes("#content a") %>%
html_attr(name = "href") %>%
head()
read_html("http://stat.iastate.edu/people/3") %>%
html_nodes("#content a") %>%
html_attr(name = "href") <- hrefs
href <- read_html("http://stat.iastate.edu/people/3") %>%
html_nodes("#content a") %>%
html_attr(name = "href")
head(hrefs)
head(href)
library('stringr')
library('tidyr')
url <- 'http://espn.go.com/nfl/superbowl/history/winners'
webpage <- read_html(url)
sb_table <- html_nodes(webpage, 'table')
dim(sb_table)
str(sb_table)
sb_table[1]
sb_table[2]
sb_table[[1]]
sb_table[[2]]
sb <- html_table(sb_table[[1]])
head(sb)
rown <- sb[2,]
rown
sb <- sb[-1:2, ]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
sb$NO. <- 1:49
dim(sb)
sb$NO. <- 1:dim(sb)
sb$NO. <- as.numeric(1:dim(sb))
?as.numeric
sb$NO. <- as.numeric(c(1:dim(sb)))
1:dim(sb)
class(1:dim(db))
class(1:dim(sb))
sb$NO. <- c(1:dim(sb))
head(sb)
tail(sb)
sb$DATE <- as.Date(sb$DATE, 'yyyy-mm-dd')
head(sb)
?as.Date
sb$DATE <- as.Date(sb$DATE, "%m/%d/%y")
head(sb)
url <- 'http://espn.go.com/nfl/superbowl/history/winners'
webpage <- read_html(url)
## 2.抓取内容html_nodes()
sb_table <- html_nodes(webpage, 'table')
## 3.把内容转换成dataframe
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
sb$NO. <- c(1:dim(sb))
sb$DATE <- as.Date(sb$DATE, "%m/%d/%y")
head(sb)
sb_table <- html_nodes(webpage, 'table')
## 3.把内容转换成dataframe
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
sb$NO. <- c(1:dim(sb))
sb$DATE <- as.Date(sb$DATE, "%B. %d, %Y")
head(sb)
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb))
sb$DATE <- as.Date(sb$DATE, "%Y-%m-%d")
head(sb)
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb))
head(sb)
sb$DATE <- as.Date(sb$DATE, "%M. %d, %Y")
head(sb)
sb_table <- html_nodes(webpage, 'table')
## 3.把内容转换成dataframe
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb))
head(sb)
sb$DATE <- as.Date(sb$DATE, "%B. %d, %Y")
head(sb)
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb))
sb$NO. <- c(1:dim(sb)[1])
head(sb)
?as.Date
sb$DATE <- as.Date(sb$DATE)
sb$DATE <- parse_date_time(sb$DATE, orders = c('Ymd', 'mdy', 'dmY', 'ymd'))
head(sb)
?parse_date_time
sb$DATE <- parse_date_time(sb$DATE, orders = c('%B. %d, %Y'))
sb$DATE <- parse_date_time(sb$DATE, orders = c('%B %d %Y'))
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb)[1])
head(sb)
dates <- c("May 27 1984", "July 7 2005")
betterDates <- as.Date(dates,
format = "%B %d %Y")
betterDates
dates <- c("May 27 1984", "July 7 2005")
betterDates <- as.Date(dates,
format = "%B %d %Y")
betterDates
dates <- c("May. 27, 1984", "July. 7, 2005")
betterDates <- as.Date(dates,
format = "%B. %d, %Y")
betterDates
sb$DATE <- parse_date_time(sb$DATE, orders = c('Ymd', 'mdy', 'dmY', 'ymd',
'%B %d %Y', "%B. %d, %Y"))
head(sb)
dates <- c("Jan. 15, 1967", "July. 7, 2005")
betterDates <- as.Date(dates,
format = "%B. %d, %Y")
betterDates
dates <- c("Jan. 15, 1969", "July. 7, 2005")
betterDates <- as.Date(dates,
format = "%B. %d, %Y")
betterDates
head(sb)
sb[!is.na(sb$DATE),]
sb_table <- html_nodes(webpage, 'table')
## 3.把内容转换成dataframe
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb)[1])
sb$DATE <- as.Date(sb$DATE, format = "%b. %d, %Y")
head(sb)
table(sb$DATE)
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb)[1])
head(sb)
sb$DATE
as.Date("Feb. 1, 2015", format = "%b. %d, %Y")
as.Date("Feb. 1, 2015", format = "%B. %d, %Y")
as.Date("Feb. 1, 2015", format = "%B%d%Y")
str(sb)
help("as.Date")
as.Date("Jan. 12, 1969", format = "%B. %d, %Y")
as.Date("Jan. 12, 1969", format = "%b. %d, %Y")
sb$DATE <- as.Date(sb$DATE, format = "%B. %d, %Y")
head(sb)
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb)[1])
head(sb)
?separate
sb <- separate(sb, RESULT, c('winner', 'loser', sep = ', ', remove = TRUE))
head(sb)
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb)[1])
sb <- separate(sb, RESULT, c('winner', 'loser'), sep = ', ', remove = TRUE)
head(sb)
pattern <- "\\d+$"
pattern
sb$winnerScore <- as.numeric(str_extract(sb$winner, pattern))
head(sb)
library('jsonlite')
jsondata <- fromJSON("https://api.github.com/users/jtleek/repos")
names(jsondata)
names(jsondata$owner)
jsondata$owner$login
myjson <- toJSON(iris, pretty = TRUE)
cat(myjson)
iris2 <- fromJSON(myjson)
head(iris2)
vignette(jsonlite)
vignette('jsonlite')
jsonlite::vignette
library('data.table')
?runif
df <- data.frame(a = rnorm(10),
b = runif(10, 1, 10),
c = letters(10))
df <- data.frame(a = rnorm(10),
b = runif(10, 1, 10),
c = letters[10])
df
df <- data.frame(a = rnorm(6),
b = runif(6, 1, 10),
c = letters[1:6])
df
dt <- data.table(a = rnorm(6),
b = runif(6, 1, 10),
c = letters[1:6])
dt
set.seed(123)
df <- data.frame(a = rnorm(6),
b = runif(6, 1, 10),
c = letters[1:6])
df
dt <- data.table(a = rnorm(6),
b = runif(6, 1, 10),
c = letters[1:6])
dt
tables()
class(df)
class(dt)
dt[2,]
dt[dt$a < 0,]
dt[, 1]
dt[, 2:3]
dt[, c(2, 3)]
dt[, w:= a^2 * 10]
dt
library(swirl)
install_from_swirl("Getting and Cleaning Data")
swirl()
mydf <- read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran, -(X:size))
filter(cran, package == 'swirl')
filter(cran, r_version == '3.1.1', country == 'US')
?Comparison
filter(cran, r_version <= '3.0.2', country == 'IN')
filter(cran, country == "US" | country == 'IN')
filter(cran, size > 100500, r_os == 'linux-gnu')
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran, !is.na(R.version))
filter(cran, !is.na(r_version))
cran2 <- select(cran, size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2, country, desc(r_version), ip_id)
cran3 <- select(cran, ip_id, package, size)
cran3
mutate(cran3, size_mb = size / 2^20)
mutate(cran3, size_mb = size / 2^20, size_gb = size_mb / 2^10)
mutate(cran3, correct_size = size + 1000)
summarize(cran, avg_size = mean(size))
summarize(cran, avg_bytes = mean(size))
swirl()
install_from_swirl("Data_Analysis")
swirl()
swirl()
install_from_swirl("Exploratory_Data_Analysis")
shiny::runApp('E:/0wlw/BI/shiny-bi/floatingfern')
swirl()
library(swirl)
swirl()
library(dplyr)
cran <- tal_df(mydf)
cran <- tbl_df(mydf)
rm(mydf)
rm("mydf")
cran
cran
group_by(cran,package)
?group_by()
help("group_by")
?group_by
by_package <- group_by(cran, package)
by_package
summarize(by_package, mean(size))
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
top_counts <- filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted <- arrange(top_counts, desc(count))
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique <- filter(pack_sum, unique > 465)
View(top_unique)
top_unique_sorted <- arrange(top_unique, desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
cran %>% select(ip_id, country, package, size) %>% print
submit()
submit()
submit()
submit()
submit()
library('rstudioapi')
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv",
destfile = './data01.csv',
method = 'curl')
list.files()
data01 <- read.csv('data01.csv',
header = TRUE)
head(data01)
dim(data01)
library('dplyr')
data01 <- tbl_df(data01)
data01
data01 %>%
filter(VAl >= 1000000) %>%
summarize(n())
data01 %>%
filter(VAL >= 1000000) %>%
summarize(n())
data01 %>%
filter(VAL >= 1000000)
data01 %>%
filter(VAL == 24) %>%
summarize(n())
table(data01$FES)
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx",
destfile = 'gov_ngap.xlsx',
method = 'curl')
gov_ngap <- read.xlsx("gov_ngap.xlsx",
header = TRUE,
colIndex = 7:15,
rowIndex = 18:23)
library("xlsx")
gov_ngap <- read.xlsx("gov_ngap.xlsx",
header = TRUE,
colIndex = 7:15,
rowIndex = 18:23)
gov_ngap <- read.xlsx("gov_ngap.xlsx",
sheetIndex = 1,
header = TRUE,
colIndex = 7:15,
rowIndex = 18:23)
gov_ngap
rm("gov_ngap")
dat <- read.xlsx("gov_ngap.xlsx",
sheetIndex = 1,
header = TRUE,
colIndex = 7:15,
rowIndex = 18:23)
sum(dat$Zip * dat$Ext, na.rm = TRUE)
fileurl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileurl, useInternal = TRUE)
library('XML')
doc <- xmlTreeParse(fileurl, useInternal = TRUE)
doc <- xmlTreeParse(fileurl, useInternal = TRUE)
library(swirl)
swirl()
shiny::runApp('E:/0wlw/Product/shiny_prototype/salesmen_analysis')
head(install.packages())
install.packages()
installed.packages()
head(installed.packages())
str(installed.packages())
head(installed.packages()[, 'package'])
head(installed.packages()[, 'Package'])
length(installed.packages())
length(installed.packages()[, 'Package'])
"ggplot2" %in% installed.packages()[, "package"]
"ggplot2" %in% installed.packages()[, "Package"]
c("ggplot2", 'ggplo', "ggp") %in% installed.packages()[, "Package"]
c("ggplot2", 'ggplo', "ggp")[c("ggplot2", 'ggplo', "ggp") %in% installed.packages()[, "Package"]]
c("ggplot2", 'ggplo', "ggp")[!(c("ggplot2", 'ggplo', "ggp") %in% installed.packages()[, "Package"])]
aa <- c("ggplot2", 'ggplo', "ggp")[!(c("ggplot2", 'ggplo', "ggp") %in% installed.packages()[, "Package"])]
length(aa)
install_pkg <- function(pkg){
# 从列出的包中筛选出还未安装的包
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
# 如果有未安装的包，则安装该包和其依赖包
if(length(new.pkg)) install.packages(new.pkg, dependencies = TRUE)
# 加载列出的所有包
sapply(pkg, library, character.only = TRUE)
}
pkg <- c("ggplot2", "RJDBC", "recharts", "dplyr", "shiny", "shinydashboard", "DT",
"leaflet", "sqldf", "tidyr", "highcharter", "reshape2", "xts", "lubridate",
"jsonlite", "networkD3")
install_pkg(pkg)
runApp('E:/0wlw/Product/shiny_prototype/salesmen_analysis')
runApp('E:/0wlw/BI/shiny-bi/floatingfern')
library('swirl')
swirl()
cars
cars$mpgCity
myMPG <- cars$mpgCity
mean(myMPG)
median(myMPG)
table(myMPG)
19
bye()
