## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb)[1])
head(sb)
?separate
sb <- separate(sb, RESULT, c('winner', 'loser', sep = ', ', remove = TRUE))
head(sb)
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb)[1])
sb <- separate(sb, RESULT, c('winner', 'loser'), sep = ', ', remove = TRUE)
head(sb)
pattern <- "\\d+$"
pattern
sb$winnerScore <- as.numeric(str_extract(sb$winner, pattern))
head(sb)
library('rvest')
library('stringr')
library('tidyr')
# simple demo ---------------------------------------------------------------------
## 数据是标准的html表格格式
## 读取网页
read_html("http://en.wikipedia.org/wiki/Table_(information)") %>%
## 抓取第一个wikitable标签的内容
html_node(".wikitable") %>%
## 把wikitable从html代码格式转换成dataframe格式
html_table()
# 流程详解 ------------------------------------------------------------------------
## 1.读取网页read_html()
url <- 'http://espn.go.com/nfl/superbowl/history/winners'
webpage <- read_html(url)
## 2.抓取内容html_nodes()
sb_table <- html_nodes(webpage, 'table')
## 3.把内容转换成dataframe
sb <- html_table(sb_table[[1]])
head(sb)
## 4.把数据整理一下
### 去掉前两行(无效数据),加上原来的列名
rown <- sb[2,]
sb <- sb[-(1:2), ]
colnames(sb) = rown
head(sb)
### 用阿拉伯数字代替罗马数字,转换日期格式
sb$NO. <- c(1:dim(sb)[1])
# sb$DATE <- as.Date(sb$DATE, format = "%B. %d, %Y") # 格式转换有问题，再看
### 把RESULT列分割成四列(winner, loser, winnerScore, loserScore)
# 先把winner和loser从result中分割出来
sb <- separate(sb, RESULT, c('winner', 'loser'), sep = ', ', remove = TRUE)
# 再来分割winner/score和loser/score
pattern <- "\\d+$"
sb$winnerScore <- as.numeric(str_extract(sb$winner, pattern))
head(sb)
sb$loserScore <- as.numeric(str_extract(sb$loser, pattern))
head(sb)
as$winner <- gsub(pattern, "", sb$winner)
as$winner <- gsub(pattern, " ", sb$winner)
?gsub
sb$winner <- gsub(pattern, " ", sb$winner)
head(sb)
sb$loser <- gsub(pattern, "", sb$loser)
head(sb)
url <- "http://www.fia.com/events/fia-formula-one-world-championship/season-2015/
race-classification-0"
fiaTableGrabber <- function(url,num){
#Grab the page
hh = html(url)
#Parse HTML
cc = html_nodes(hh, xpath = "//table")[[num]] %>%
html_table(fill=TRUE)
#Set the column names
colnames(cc) = cc[1, ]
#Drop all NA column
cc = Filter(function(x)!all(is.na(x)), cc[-1,])
#Fill blanks with NA
cc = apply(cc, 2, function(x) gsub("^$|^ $", NA, x))
#would the dataframe cast handle the NA?
as.data.frame(cc)
}
NUM <- 10
xx=fiaTableGrabber(url,NUM)
url <- "http://www.fia.com/events/fia-formula-one-world-championship/season-2015/race-classification-0"
xx <- fiaTableGrabber(url,NUM)
cc = html_nodes(hh, xpath = "table")[[num]] %>%
html_table(fill=TRUE)
fiaTableGrabber <- function(url,num){
#Grab the page
hh = html(url)
#Parse HTML
cc = html_nodes(hh, xpath = "table")[[num]] %>%
html_table(fill=TRUE)
#Set the column names
colnames(cc) = cc[1, ]
#Drop all NA column
cc = Filter(function(x)!all(is.na(x)), cc[-1,])
#Fill blanks with NA
cc = apply(cc, 2, function(x) gsub("^$|^ $", NA, x))
#would the dataframe cast handle the NA?
as.data.frame(cc)
}
NUM <- 10
xx <- fiaTableGrabber(url,NUM)
fiaTableGrabber <- function(url,num){
#Grab the page
hh = read_html(url)
#Parse HTML
cc = html_nodes(hh, xpath = "table")[[num]] %>%
html_table(fill=TRUE)
#Set the column names
colnames(cc) = cc[1, ]
#Drop all NA column
cc = Filter(function(x)!all(is.na(x)), cc[-1,])
#Fill blanks with NA
cc = apply(cc, 2, function(x) gsub("^$|^ $", NA, x))
#would the dataframe cast handle the NA?
as.data.frame(cc)
}
xx <- fiaTableGrabber(url,NUM)
head(xx)
hh = read_html(url)
cc = html_nodes(hh, xpath = "table")[[1]] %>%
html_table(fill=TRUE)
?html_nodes
cc = html_nodes(hh, xpath = "//table")[[1]] %>%
html_table(fill=TRUE)
head(xx)
head(c)
head(cc)
colnames(cc) = cc[1, ]
head(cc)
cc = Filter(function(x)!all(is.na(x)), cc[-1,])
head(cc)
cc = apply(cc, 2, function(x) gsub("^$|^ $", NA, x))
as.data.frame(cc)
legomovie <- read_html("http://www.imdb.com/title/tt1490017/")
legomovie %>%
html_node("strong span") %>%
html_text() %>%
as.numeric()
legomovie %>%
html_node("span") %>%
html_text() %>%
as.numeric()
legomovie %>%
html_node("strong span") %>%
html_text()
legomovie %>%
html_node("span a") %>%
html_text() %>%
as.numeric()
legomovie %>%
html_node("span a") %>%
html_text() %>%
as.numeric()
legomovie %>%
html_node("h1,a") %>%
html_text()
legomovie %>%
html_node(".subtext a") %>%
html_text()
legomovie %>%
html_node("h1,.subtext a") %>%
html_text()
legomovie %>%
html_node("span,.subtext a") %>%
html_text() %>%
as.numeric()
legomovie %>%
html_node(".ratingValue span") %>%
html_text() %>%
as.numeric()
legomovie %>%
html_node("span a") %>%
html_text()
legomovie %>%
html_node("strong span") %>%
html_text() %>%
as.numeric()
legomovie %>%
html_node("#titleCast , .itemprop , .character") %>%
html_table()
legomovie %>%
html_node("#titleCast , .itemprop , .character")[[1]] %>%
html_table()
legomovie %>%
html_node("#titleCast , .itemprop , .character")[[1]]
legomovie %>%
html_node("#titleCast .itemprop .character")[[1]] %>%
html_table()
legomovie %>%
html_node("#titleCast .itemprop span") %>%
html_text()
legomovie %>%
html_nodes("#titleCast .itemprop span") %>%
html_text()
legomovie %>%
html_nodes("#titleCast .itemprop span .character tr td") %>%
html_text()
legomovie %>%
html_nodes("#titleCast .character") %>%
html_text()
legomovie %>%
html_nodes("#titleCast .character") %>%
html_text() %>%
head()
legomovie %>%
html_nodes("#titleCast .character a") %>%
html_text() %>%
head()
legomovie %>%
html_nodes("#titleCast .character a a") %>%
html_text() %>%
head()
legomovie %>%
html_nodes("#titleCast .character div a") %>%
html_text() %>%
head()
legomovie %>%
html_nodes("#titleCasr .itemprop") %>%
html_text()
legomovie %>%
html_nodes("#titleCast .itemprop") %>%
html_text()
legomovie %>%
html_nodes("#titleCast .itemprop span") %>%
html_text()
legomovie %>%
html_nodes("#titleCast .character") %>%
html_text() %>%
as.data.frame()
legomovie %>%
html_nodes("#titleCast .itemprop span") %>%
html_text() %>%
as.data.frame()
legomovie %>%
html_nodes("#titleCast .itemprop span") %>%
html_text()
legomovie %>%
html_nodes("#titleCast .character div") %>%
html_text()
legomovie %>%
html_nodes("#titleCast .character div") %>%
html_text() %>%
head()
legomovie %>%
html_nodes("#titleCast .character div") %>%
html_text() %>%
head() %>%
dim()
legomovie %>%
html_nodes("#titleCast .character div") %>%
html_text() %>%
head()
legomovie %>%
html_nodes("#titleCast .character") %>%
html_text() %>%
head()
legomovie %>%
html_nodes("table") %>%
.[[3]] %>%
html_table()
legomovie %>%
html_nodes("table") %>%
.[[1]] %>%
html_table()
legomovie %>%
html_nodes("table") %>%
.[[2]] %>%
html_table()
demo(package = "rvest")
demo(zillow)
library(readR)
library(readr)
demo(zillow)
head(houses)
head(z_id)
library('swirl')
library('swirl')
ls()
rm(list = ls())
swirl()
swirl()
x <- c(44, NA, 5, NA)
x * 3
y <- rnorm(1000)
z <- rep(NA, 1000)
ma_data <- sample(c(y, z), 100)
ma_data <- sample(c(y, z), 100)
info()
my_data <- sample(c(y, z), 100)
is.na(my_data)
my_na <- is.na(my_data)
my_na
my_na <- my_data == NA
my_data == NA
sum(my_na)
my_date
my_data
0/0
1/0
NA
Inf/Inf
Inf-Inf
d1 <- Sys.Date()
class(d1)
unclass(d1)
d1
d2 <- as.Date('1969-01-01')
unclass(d2)
t1 <- Sys.time()
t1
class(t1)
unclass(t1)
t2 <- as.POSIXlt(Sys.time())
t2
class(t2)
t2
unclass(t2)
str(unclass(t2))
t2$min
weekdays(d1)
months(t1)
quaters(t2)
quarters(t2)
t3 <- "October 17, 1986 08:24"
strptime(t3, "%B %d, %Y %H:%M")
t4 <- strptime(t3, "%B %d, %Y %H:%M")
t4
class(t4)
Sys.time()>t1
Sys.time() - t1
difftime(Sys.time(), t1, units = 'days')
swirl()
byw()
bye()
rm(list = ls())
getwd()
setwd("../")
getwd()
setwd('./')
getwd()
setwd('./data')
choose.dir()
list.files()
this.dir <- dirname(parent.frame(2)$ofile)
parent.frame(2)
parent.frame(2)$ofile
parent.frame()
?parent.frame
frame_files <- lapply(sys.frames(), function(x) x$ofile)
frame_files <- Filter(Negate(is.null), frame_files)
TOPDIR <- dirname(frame_files[[length(frame_files)]])
frame_files
sys.frames()
this.dir <- dirname(parent.frame(1)$ofile)
this.dir <- dirname(sys.frame(1)$ofile)
sys.call()
sys.call(which = 0)
sys.call(which = 1\)
sys.call(which = 1)
sys.frame()
sys.frames()
sys.frame(1)
sys.frame()$ofile
dim(sys.frame())
class(sys.frame())
str(sys.frame())
install.packages("rstudioapi")
library(rstudioapi)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
getActiveDocumentContext()
getActiveDocumentContext()$path
dirname(getActiveDocumentContext()$path)
rstudioapi::getActiveDocumentContext()
rstudioapi::getActiveDocumentContext()$path
dirname(rstudioapi::getActiveDocumentContext()$path)
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
download.file(fileurl, destfile = 'cameras.csv', method = 'curl')
fileurl <- "https://data.baltimorecity.gov/Transportation/Baltimore-Fixed-Speed-Cameras/dz54-2aru"
download.file(fileurl, destfile = 'cameras.csv', method = 'curl')
list.files()
download.file(fileurl, destfile = './cameras.csv', method = 'curl')
list.files()
fileurl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/row.csv?accessType=DOWNLOAD"
download.file(fileurl, destfile = './cameras.csv', method = 'curl')
list.files()
download.file(fileurl, destfile = 'cameras.csv', method = 'curl')
fileurl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/row.csv?accessType=DOWNLOAD"
download.file(fileurl, destfile = './cameras.csv', method = 'curl')
list.files()
fileurl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(fileurl, destfile = './cameras.csv', method = 'curl')
list.files()
url <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
download.file(url, destfile = 'hh.csv', method = 'curl')
fileurl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD&bom=true"
download.file(fileurl, destfile = './cameras.csv', method = 'curl')
read.table(file = 'Baltimore_Fixed_Speed_Cameras.csv',
sep = ',',
header = TRUE)
cameras <- read.table(file = 'Baltimore_Fixed_Speed_Cameras.csv',
sep = ',',
header = TRUE)
head(cameras)
cameras <- read.csv(file = 'Baltimore_Fixed_Speed_Cameras.csv',
header = TRUE)
head(cameras)
sum(is.na(cameras))
library('rstudioapi')
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
library(xlsx)
library("xlsx")
?read.xlsx
cameras <- read.xlsx(file = "Baltimore_Fixed_Speed_Cameras.xlsx",
sheetIndex = 1,
header = TRUE)
head(cameras)
str(cameras)
colindexs <- c(1:3)
rowindexs <- c(3:5)
read.xlsx(file = "Baltimore_Fixed_Speed_Cameras.xlsx",
sheetIndex = 1,
colIndex = colindexs,
rowIndex = rowIndex)
read.xlsx(file = "Baltimore_Fixed_Speed_Cameras.xlsx",
sheetIndex = 1,
colIndex = colindexs,
rowIndex = rowindexs)
rowindexs <- c(1:5)
read.xlsx(file = "Baltimore_Fixed_Speed_Cameras.xlsx",
sheetIndex = 1,
colIndex = colindexs,
rowIndex = rowindexs)
colindexs <- c(2:3)
read.xlsx(file = "Baltimore_Fixed_Speed_Cameras.xlsx",
sheetIndex = 1,
colIndex = colindexs,
rowIndex = rowindexs)
read.xlsx(file = "Baltimore_Fixed_Speed_Cameras.xlsx",
sheetIndex = 1,
startRow = 2,
colIndex = colindexs,
rowIndex = rowindexs)
read.xlsx(file = "Baltimore_Fixed_Speed_Cameras.xlsx",
sheetIndex = 1,
startRow = 5,
colIndex = colindexs,
rowIndex = rowindexs)
class(cameras)
read.xlsx(file = "Baltimore_Fixed_Speed_Cameras.xlsx",
header = FALSE,
sheetIndex = 1,
colIndex = colindexs,
rowIndex = rowindexs)
library('xml')
library('XML')
fileurl <- "https://www.w3schools.com/xml/simple.xml"
doc <- xmlTreeParse(fileurl, useInternal = TRUE)
doc <- xmlTreeParse(fileurl, useInternalNodes =  = TRUE)
doc <- xmlTreeParse(fileurl, useInternalNodes = TRUE)
?xmlTreeParse
fileurl <- "http://w3school.com.cn/example/xmle/note.xml"
doc <- xmlTreeParse(fileurl, useInternalNodes = TRUE)
doc <- xmlTreeParse(fileurl, useInternal = TRUE)
rootnode <- xmlRoot(doc)
xmlName(rootnode)
names(rootnode)
rootnode[[1]]
fileurl <- "http://w3school.com.cn/example/xmle/simple.xml"
doc <- xmlTreeParse(fileurl, useInternal = TRUE)
rootnode <- xmlRoot(doc)
xmlName(rootnode)
names(rootnode)
rootnode[[1]]
rootNode <- xmlRoot(doc)
xmlName(rootNode)
names(rootNode)
rootNode[[1]]
rootNode[[1]][1]
xmlSApply(rootNode, xmlvalue)
xmlSApply(rootNode, xmlValue)
xpathSApply(rootNode, "//name", xmlValue)
xpathSApply(rootNode, "//price", xmlValue)
doc <- htmlTreeParse(fileurl, useInternal = TRUE)
scores <- xpathSApply(doc, "//li[@class='score']", xmlValue)
teams <- xpathSApply(doc, "//li[@class='team-name']", xmlValue)
scores
fileurl <- "http://espn.go.com/nfl/team/_/name/bal/baltimore-ravens"
doc <- htmlTreeParse(fileurl, useInternal = TRUE)
scores <- xpathSApply(doc, "//li[@class='score']", xmlValue)
teams <- xpathSApply(doc, "//li[@class='team-name']", xmlValue)
scores
scores <- xpathSApply(doc, "//li[@class='scores']", xmlValue)
scores
doc <- htmlTreeParse(fileurl, useInternal = TRUE)
scores <- xpathSApply(doc, "//li[@class='scores']", xmlValue)
scores
teams
